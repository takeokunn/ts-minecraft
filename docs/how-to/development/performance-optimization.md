---
title: 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–å®Ÿè·µã‚¬ã‚¤ãƒ‰'
description: 'TypeScript Minecraftãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Effect-TS 3.17+ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã€‚ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã€ä¸¦åˆ—å‡¦ç†ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§èƒ½æœ€é©åŒ–ã‚’å®Ÿè£…'
category: 'guide'
difficulty: 'advanced'
tags: ['performance', 'optimization', 'effect-ts', 'profiling', 'memory-management', 'concurrency', 'real-time']
prerequisites: ['development-conventions', 'effect-ts-fundamentals', 'testing-guide']
estimated_reading_time: '25åˆ†'
related_patterns: ['optimization-patterns-latest', 'service-patterns-catalog']
related_docs: ['./02-testing-guide.md', '../explanations/architecture/06-effect-ts-patterns.md']
---

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–å®Ÿè·µã‚¬ã‚¤ãƒ‰

## ğŸ¯ Problem Statement

ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚²ãƒ¼ãƒ ã‚¨ãƒ³ã‚¸ãƒ³ã«ãŠã‘ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª²é¡Œï¼š

- **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‰ãƒ­ãƒƒãƒ—**: 60FPSç¶­æŒã®ãŸã‚ã®å³æ ¼ãªæ™‚é–“åˆ¶ç´„
- **ãƒ¡ãƒ¢ãƒªåœ§è¿«**: å¤§é‡ã®ã‚²ãƒ¼ãƒ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã‚ˆã‚‹GCåœ§åŠ›
- **CPUè² è·**: è¤‡é›‘ãªç‰©ç†æ¼”ç®—ã¨æç”»å‡¦ç†ã®è² è·
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ãƒ»ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚µã‚¤ã‚ºã®å¢—åŠ ã¸ã®å¯¾å¿œ
- **ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–æ€§**: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¸ã®å³åº§ã®å¿œç­”

## ğŸš€ Solution Approach

Effect-TS 3.17+ã¨æœ€æ–°æœ€é©åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹é«˜æ€§èƒ½åŒ–ï¼š

1. **Structure of Arrays (SoA)** - ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ã®æœ€é©åŒ–
2. **Worker Poolç®¡ç†** - CPUé›†ç´„çš„å‡¦ç†ã®åˆ†æ•£
3. **ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«** - GCåœ§åŠ›ã®è»½æ¸›
4. **Batch Processing** - I/Oå‡¦ç†ã®åŠ¹ç‡åŒ–
5. **Performance Budgeting** - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¶ç´„ã®ç®¡ç†

## âš¡ Quick Guide (5åˆ†)

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

- [ ] **ãƒ–ãƒ©ã‚¦ã‚¶DevTools** - åŸºæœ¬çš„ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
- [ ] **Performance API** - æ­£ç¢ºãªæ™‚é–“æ¸¬å®š
- [ ] **Memory API** - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
- [ ] **Custom Metrics** - ã‚²ãƒ¼ãƒ å›ºæœ‰æŒ‡æ¨™
- [ ] **Real-time Monitoring** - ç¶™ç¶šçš„ãªç›£è¦–

#### å³åº§ã«å®Ÿè¡Œå¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰é›†

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ“ãƒ«ãƒ‰ + ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
pnpm build --analyze

# é–‹ç™ºã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼‰
DEBUG=minecraft:performance pnpm dev

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pnpm test:performance

# ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºåˆ†æ
pnpx webpack-bundle-analyzer dist/stats.json

# TypeScript ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“æ¸¬å®š
pnpx tsc --diagnostics

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
node --inspect --max-old-space-size=4096 dist/main.js

# CPU ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
node --prof dist/main.js && node --prof-process isolate-*.log > profile.txt

# Three.js ã®ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç›£è¦–
DEBUG=three:* pnpm dev
```

#### ç¶™ç¶šçš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

```bash
# GitHub Actionsã§ã®è‡ªå‹•è¨ˆæ¸¬
.github/workflows/performance.yml ã§è¨­å®š

# Lighthouse CI ã§ã®å®šæœŸæ¸¬å®š
pnpx lhci autorun

# Bundle Buddy ã«ã‚ˆã‚‹ãƒãƒ³ãƒ‰ãƒ«åˆ†æ
pnpx bundle-buddy dist/main.js
```

### åŸºæœ¬æœ€é©åŒ–ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```typescript
// 1. Effect-TS Schema ã«ã‚ˆã‚‹å‹å®‰å…¨ãƒã‚§ãƒƒã‚¯
const isValidEntity = Schema.is(EntitySchema)
const parseEntity = Schema.decodeUnknown(EntitySchema)
const validateEntityData = Schema.decodeUnknown(EntityDataSchema)

// 2. åŠ¹ç‡çš„ãªãƒãƒƒãƒå‡¦ç†ï¼ˆå‹å®‰å…¨ï¼‰
const processBatch = <T, R, E, Ctx>(
  items: ReadonlyArray<T>,
  processor: (batch: ReadonlyArray<T>) => Effect.Effect<ReadonlyArray<R>, E, Ctx>,
  batchSize: number & Brand.Brand<'BatchSize'> = 100 as any
): Effect.Effect<ReadonlyArray<R>, E, Ctx> =>
  Effect.gen(function* () {
    const results: R[] = []

    // Array.chunksOf + Effect.forEach ã«ã‚ˆã‚‹ä¸¦åˆ—ãƒãƒƒãƒå‡¦ç†
    const chunks = Array.chunksOf(items, batchSize)
    const results: R[] = []

    yield* Effect.forEach(
      chunks,
      (batch) =>
        Effect.gen(function* () {
          const batchResults = yield* processor(batch)
          results.push(...batchResults)
        }),
      { concurrency: 'unbounded' } // ä¸¦åˆ—å‡¦ç†ã§æ€§èƒ½å‘ä¸Š
    )

    return results
  })

// 3. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªSoAæ§‹é€ ï¼ˆå‹å®‰å…¨ï¼‰
export const ComponentStoreSchema = <T>() =>
  Schema.Struct({
    data: Schema.Union(Schema.instanceOf(Float32Array), Schema.instanceOf(Int32Array), Schema.instanceOf(Uint32Array)),
    indices: Schema.instanceOf(Map<EntityId, number>),
    count: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('ComponentCount')),
    capacity: Schema.Number.pipe(Schema.int(), Schema.positive(), Schema.brand('ComponentCapacity')),
  }).pipe(
    Schema.filter(
      (store) => {
        return store.count <= store.capacity && store.indices.size <= store.count
      },
      {
        message: () => 'ComponentStore ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ',
      }
    ),
    Schema.identifier('ComponentStore'),
    Schema.description('ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç”¨SoAã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸')
  )

interface ComponentStore<T> {
  readonly data: Float32Array | Int32Array | Uint32Array
  readonly indices: Map<EntityId, number>
  readonly count: number & Brand.Brand<'ComponentCount'>
  readonly capacity: number & Brand.Brand<'ComponentCapacity'>
}
```

#### ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚³ãƒãƒ³ãƒ‰

```bash
# å³åº§ã«ä½¿ç”¨å¯èƒ½ãªãƒ‡ãƒãƒƒã‚°ã‚³ãƒãƒ³ãƒ‰

# 1. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º
node --trace-gc --trace-gc-verbose dist/main.js 2>&1 | grep "GC"

# 2. V8 ãƒ’ãƒ¼ãƒ—ãƒ€ãƒ³ãƒ—ç”Ÿæˆ
node --inspect --heapdump-on-out-of-memory dist/main.js

# 3. Effect-TSãƒˆãƒ¬ãƒ¼ã‚¹æœ‰åŠ¹åŒ–
DEBUG=effect:* pnpm dev

# 4. Three.js ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çµ±è¨ˆ
window.performance.mark('render-start')
window.performance.mark('render-end')
window.performance.measure('render-duration', 'render-start', 'render-end')

# 5. Webpackãƒãƒ³ãƒ‰ãƒ«æœ€é©åŒ–
pnpx webpack-bundle-analyzer --port 8888

# 6. TypeScriptå‹ãƒã‚§ãƒƒã‚¯æ™‚é–“æ¸¬å®š
time pnpm typecheck

# 7. ESLint ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
DEBUG=eslint:cli-engine pnpm lint

# 8. Vitestå®Ÿè¡Œæ™‚é–“ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
pnpm test --reporter=verbose --run
```

## ğŸ“‹ Detailed Instructions

### Step 0: å³åº§å®Ÿè¡Œ - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã®ç·Šæ€¥è¨ºæ–­

```bash
# ğŸš¨ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆä½ä¸‹ã®ç·Šæ€¥è¨ºæ–­
# ãƒ–ãƒ©ã‚¦ã‚¶ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§å³åº§ã«å®Ÿè¡Œå¯èƒ½

# 1. FPSç›£è¦–é–‹å§‹
let frameCount = 0;
let lastTime = performance.now();
const measureFPS = () => {
  frameCount++;
  const currentTime = performance.now();
  pipe(
    currentTime - lastTime >= 1000,
    Match.boolean({
      onTrue: () => {
        console.log(`FPS: ${Math.round(frameCount * 1000 / (currentTime - lastTime))}`);
        frameCount = 0;
        lastTime = currentTime;
      },
      onFalse: () => {}
    })
  )
  requestAnimationFrame(measureFPS);
};
measureFPS();

# 2. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
setInterval(() => {
  pipe(
    performance.memory,
    Option.fromNullable,
    Option.match({
      onNone: () => {},
      onSome: (memory) => {
        console.log(`Memory: ${Math.round(memory.usedJSHeapSize / 1024 / 1024)}MB`);
      }
    })
  )
}, 1000);

# 3. ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
const stats = renderer.info;
console.log(`Draw Calls: ${stats.render.calls}, Triangles: ${stats.render.triangles}`);

# 4. WebGL ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
const gl = renderer.getContext();
console.log('WebGL Info:', {
  renderer: gl.getParameter(gl.RENDERER),
  vendor: gl.getParameter(gl.VENDOR),
  version: gl.getParameter(gl.VERSION)
});
```

### Step 1: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

åŒ…æ‹¬çš„ãªæ€§èƒ½è¨ˆæ¸¬ç’°å¢ƒã‚’æ§‹ç¯‰ï¼š

```typescript
// src/performance/profiler.ts
import { Effect, Context, Layer, Schema, Match, Option, pipe, Brand } from "effect"
import type { ParseError } from "@effect/schema/ParseResult"

// è¨ˆæ¸¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å®šç¾©
export const PerformanceMetricCategorySchema = Schema.Literal("cpu", "memory", "network", "rendering", "physics")
export const PerformanceMetricUnitSchema = Schema.Literal("ms", "mb", "fps", "ops/sec", "percent")

export const PerformanceMetricSchema = Schema.Struct({
  name: Schema.String.pipe(
    Schema.minLength(1),
    Schema.maxLength(100),
    Schema.brand("MetricName")
  ),
  category: PerformanceMetricCategorySchema,
  value: Schema.Number.pipe(
    Schema.nonnegative(),
    Schema.brand("MetricValue")
  ),
  unit: PerformanceMetricUnitSchema,
  timestamp: Schema.Number.pipe(
    Schema.positive(),
    Schema.brand("Timestamp")
  ),
  metadata: Schema.optional(Schema.Record(Schema.String, Schema.Unknown))
}).pipe(
  Schema.identifier("PerformanceMetric"),
  Schema.description("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¾ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒ")
)

export type PerformanceMetric = Schema.Schema.Type<typeof PerformanceMetricSchema>
export type PerformanceMetricCategory = Schema.Schema.Type<typeof PerformanceMetricCategorySchema>
export type PerformanceMetricUnit = Schema.Schema.Type<typeof PerformanceMetricUnitSchema>

// ğŸš€ ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œä¾‹
// ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼èµ·å‹•: DEBUG=profiler:* pnpm dev
// ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‡ºåŠ›: node -e "console.log(JSON.stringify(metrics, null, 2))" > metrics.json
// åˆ†æå®Ÿè¡Œ: pnpm analyze-performance metrics.json

// ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹
export interface ProfilerService {
  readonly startProfiling: (sessionName: string) => Effect.Effect<ProfilingSession, ProfilerError>
  readonly stopProfiling: (sessionId: string) => Effect.Effect<ProfilingResult, ProfilerError>
  readonly recordMetric: (metric: PerformanceMetric) => Effect.Effect<void, never>
  readonly getMetrics: (filter?: MetricFilter) => Effect.Effect<ReadonlyArray<PerformanceMetric>, never>
  readonly startRealTimeMonitoring: (config: MonitoringConfig) => Effect.Effect<void, ProfilerError>
}

export const ProfilerService = Context.GenericTag<ProfilerService>("@minecraft/ProfilerService")

// ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°è¨­å®šã®å‹å®‰å…¨ãªå®šç¾©
export const ProfilingConfigSchema = Schema.Struct({
  enableCPUProfiling: Schema.Boolean,
  enableMemoryProfiling: Schema.Boolean,
  enableNetworkProfiling: Schema.optional(Schema.Boolean),
  sampleRate: Schema.Number.pipe(
    Schema.int(),
    Schema.positive(),
    Schema.brand("SampleRate")
  ),
  maxSamples: Schema.optional(Schema.Number.pipe(
    Schema.int(),
    Schema.positive(),
    Schema.brand("MaxSamples")
  )),
  autoStop: Schema.optional(Schema.Boolean),
  outputFormat: Schema.optional(Schema.Literal("json", "csv", "flamegraph"))
}).pipe(
  Schema.identifier("ProfilingConfig"),
  Schema.description("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¨­å®š")
)

export const ProfilingSessionIdSchema = Schema.String.pipe(
  Schema.pattern(/^session-\d+-[a-z0-9]+$/),
  Schema.brand("ProfilingSessionId")
)

// ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³
export const ProfilingSessionSchema = Schema.Struct({
  id: ProfilingSessionIdSchema,
  name: Schema.String.pipe(
    Schema.minLength(1),
    Schema.maxLength(100),
    Schema.brand("SessionName")
  ),
  startTime: Schema.Number.pipe(
    Schema.positive(),
    Schema.brand("Timestamp")
  ),
  config: ProfilingConfigSchema,
  status: Schema.Literal("active", "completed", "failed", "aborted"),
  endTime: Schema.optional(Schema.Number.pipe(
    Schema.positive(),
    Schema.brand("Timestamp")
  ))
}).pipe(
  Schema.filter((session) => {
    return !session.endTime || session.endTime >= session.startTime
  }, {
    message: () => "çµ‚äº†æ™‚åˆ»ã¯é–‹å§‹æ™‚åˆ»ã‚ˆã‚Šå¾Œã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
  }),
  Schema.identifier("ProfilingSession"),
  Schema.description("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å®šç¾©")
)

export type ProfilingConfig = Schema.Schema.Type<typeof ProfilingConfigSchema>
export type ProfilingSession = Schema.Schema.Type<typeof ProfilingSessionSchema> & {
  measure: <A, E>(
    operation: Effect.Effect<A, E>,
    operationName: string
  ) => Effect.Effect<A, E>
  measure = <A, E>(
    operation: Effect.Effect<A, E>,
    operationName: string
  ): Effect.Effect<A, E> => Effect.gen(function* () {
    const startTime = performance.now()
    const startMemory = (performance as any).memory?.usedJSHeapSize || 0

    const result = yield* operation

    const endTime = performance.now()
    const endMemory = (performance as any).memory?.usedJSHeapSize || 0

    yield* ProfilerService.recordMetric({
      name: operationName,
      category: "cpu",
      value: endTime - startTime,
      unit: "ms",
      timestamp: Date.now(),
      metadata: {
        sessionId: this.id,
        memoryDelta: endMemory - startMemory
      }
    })

    return result
  })
}

// ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ã®å®Ÿè£…
const makeProfilerServiceLive = Effect.gen(function* () {
  const metrics = new Map<string, PerformanceMetric[]>()
  const sessions = new Map<string, ProfilingSession>()

  return ProfilerService.of({
    startProfiling: (sessionName) => Effect.gen(function* () {
      const sessionId = `session-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`

      const session = new ProfilingSession({
        id: sessionId,
        name: sessionName,
        startTime: performance.now(),
        config: {
          enableCPUProfiling: true,
          enableMemoryProfiling: true,
          sampleRate: 1000 // 1ç§’é–“éš”
        }
      })

      sessions.set(sessionId, session)
      yield* Effect.logInfo(`Profiling session started: ${sessionName} (${sessionId})`)

      return session
    }),

    stopProfiling: (sessionId) => Effect.gen(function* () {
      const session = sessions.get(sessionId)

      return yield* pipe(
        session,
        Option.fromNullable,
        Option.match({
          onNone: () => Effect.fail(new ProfilerError({
            operation: "stopProfiling",
            reason: "Session not found",
            sessionId
          })),
          onSome: (sessionValue) => Effect.succeed(sessionValue)
        }),
        Effect.flatMap((sessionValue) => Effect.gen(function* () {

      const endTime = performance.now()
      const duration = endTime - session.startTime
      const sessionMetrics = metrics.get(sessionId) || []

      sessions.delete(sessionId)

      yield* Effect.logInfo(`Profiling session completed: ${session.name} (${duration.toFixed(2)}ms)`)

      return {
        sessionId,
        sessionName: session.name,
        duration,
        totalMetrics: sessionMetrics.length,
        metrics: sessionMetrics,
        summary: generatePerformanceSummary(sessionMetrics)
      }
    }),

    recordMetric: (metric) => Effect.gen(function* () {
      const sessionId = metric.metadata?.sessionId as string || "global"

      pipe(
        metrics.has(sessionId),
        Match.boolean({
          onTrue: () => {},
          onFalse: () => metrics.set(sessionId, [])
        })
      )

      metrics.get(sessionId)!.push(metric)

      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã¸ã®é€šçŸ¥
      yield* notifyRealTimeMonitors(metric)
    }),

    getMetrics: (filter) => Effect.gen(function* () {
      const allMetrics = Array.from(metrics.values()).flat()

      return pipe(
        filter,
        Option.fromNullable,
        Option.match({
          onNone: () => allMetrics,
          onSome: (filterValue) => filterValue
        })
      )

      return allMetrics.filter(metric =>
        (!filter.category || metric.category === filter.category) &&
        (!filter.namePattern || metric.name.includes(filter.namePattern)) &&
        (!filter.timeRange || (
          metric.timestamp >= filter.timeRange.start &&
          metric.timestamp <= filter.timeRange.end
        ))
      )
    }),

    startRealTimeMonitoring: (config) => Effect.gen(function* () {
      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ«ãƒ¼ãƒ—ã®é–‹å§‹
      yield* Effect.fork(
        realTimeMonitoringLoop(config).pipe(
          Effect.forever,
          Effect.catchAll(error =>
            Effect.logError(`Real-time monitoring error: ${error}`)
          )
        )
      )

      yield* Effect.logInfo("Real-time performance monitoring started")
    })
  })
})

export const ProfilerServiceLive = Layer.effect(ProfilerService, makeProfilerServiceLive)

// ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ«ãƒ¼ãƒ—
const realTimeMonitoringLoop = (config: MonitoringConfig) => Effect.gen(function* () {
  // ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆæ¸¬å®š
  const fps = yield* measureFrameRate()
  yield* ProfilerService.recordMetric({
    name: "frame-rate",
    category: "rendering",
    value: fps,
    unit: "fps",
    timestamp: Date.now()
  })

  // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
  yield* pipe(
    (performance as any).memory,
    Option.fromNullable,
    Option.match({
      onNone: () => Effect.unit,
      onSome: (memoryInfo) => ProfilerService.recordMetric({
        name: "heap-used",
      category: "memory",
      value: memoryInfo.usedJSHeapSize / 1024 / 1024, // MB
      unit: "mb",
      timestamp: Date.now()
    })
  }

  // CPUä½¿ç”¨ç‡ã®æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
  const cpuUsage = yield* estimateCPUUsage()
  yield* ProfilerService.recordMetric({
    name: "cpu-usage",
    category: "cpu",
    value: cpuUsage,
    unit: "percent",
    timestamp: Date.now()
  })

  // æŒ‡å®šé–“éš”ã§å¾…æ©Ÿ
  yield* Effect.sleep(`${config.intervalMs} millis`)
})
```

### Step 2: Structure of Arrays (SoA) æœ€é©åŒ–

ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼š

```typescript
// src/performance/soa-optimization.ts
import { Effect } from "effect"

// ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®SoAæ§‹é€ 
export const PositionStoreSchema = Schema.Struct({
  x: Schema.instanceOf(Float32Array).pipe(
    Schema.description("Xåº§æ¨™ã®Float32Arrayé…åˆ—")
  ),
  y: Schema.instanceOf(Float32Array).pipe(
    Schema.description("Yåº§æ¨™ã®Float32Arrayé…åˆ—")
  ),
  z: Schema.instanceOf(Float32Array).pipe(
    Schema.description("Zåº§æ¨™ã®Float32Arrayé…åˆ—")
  ),
  count: Schema.Number.pipe(
    Schema.int(),
    Schema.nonnegative(),
    Schema.brand("EntityCount")
  ),
  capacity: Schema.Number.pipe(
    Schema.int(),
    Schema.positive(),
    Schema.brand("StoreCapacity")
  )
}).pipe(
  Schema.filter((store) => {
    const expectedLength = store.capacity
    return store.x.length === expectedLength &&
           store.y.length === expectedLength &&
           store.z.length === expectedLength &&
           store.count <= store.capacity
  }, {
    message: () => "PositionStoreé…åˆ—ã®é•·ã•ã¨ã‚«ã‚¦ãƒ³ãƒˆãŒä¸€è‡´ã—ã¾ã›ã‚“"
  }),
  Schema.identifier("PositionStore"),
  Schema.description("ä½ç½®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®Structure of Arraysæ ¼ç´")
)

export const VelocityStoreSchema = Schema.Struct({
  x: Schema.instanceOf(Float32Array).pipe(
    Schema.description("Xé€Ÿåº¦ã®Float32Arrayé…åˆ—")
  ),
  y: Schema.instanceOf(Float32Array).pipe(
    Schema.description("Yé€Ÿåº¦ã®Float32Arrayé…åˆ—")
  ),
  z: Schema.instanceOf(Float32Array).pipe(
    Schema.description("Zé€Ÿåº¦ã®Float32Arrayé…åˆ—")
  ),
  count: Schema.Number.pipe(
    Schema.int(),
    Schema.nonnegative(),
    Schema.brand("EntityCount")
  ),
  capacity: Schema.Number.pipe(
    Schema.int(),
    Schema.positive(),
    Schema.brand("StoreCapacity")
  )
}).pipe(
  Schema.filter((store) => {
    const expectedLength = store.capacity
    return store.x.length === expectedLength &&
           store.y.length === expectedLength &&
           store.z.length === expectedLength &&
           store.count <= store.capacity
  }, {
    message: () => "VelocityStoreé…åˆ—ã®é•·ã•ã¨ã‚«ã‚¦ãƒ³ãƒˆãŒä¸€è‡´ã—ã¾ã›ã‚“"
  }),
  Schema.identifier("VelocityStore"),
  Schema.description("é€Ÿåº¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®Structure of Arraysæ ¼ç´")
)

export const HealthStoreSchema = Schema.Struct({
  current: Schema.instanceOf(Float32Array).pipe(
    Schema.description("ç¾åœ¨ãƒ˜ãƒ«ã‚¹ã®Float32Arrayé…åˆ—")
  ),
  maximum: Schema.instanceOf(Float32Array).pipe(
    Schema.description("æœ€å¤§ãƒ˜ãƒ«ã‚¹ã®Float32Arrayé…åˆ—")
  ),
  count: Schema.Number.pipe(
    Schema.int(),
    Schema.nonnegative(),
    Schema.brand("EntityCount")
  ),
  capacity: Schema.Number.pipe(
    Schema.int(),
    Schema.positive(),
    Schema.brand("StoreCapacity")
  )
}).pipe(
  Schema.filter((store) => {
    const expectedLength = store.capacity
    return store.current.length === expectedLength &&
           store.maximum.length === expectedLength &&
           store.count <= store.capacity
  }, {
    message: () => "HealthStoreé…åˆ—ã®é•·ã•ã¨ã‚«ã‚¦ãƒ³ãƒˆãŒä¸€è‡´ã—ã¾ã›ã‚“"
  }),
  Schema.identifier("HealthStore"),
  Schema.description("ãƒ˜ãƒ«ã‚¹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®Structure of Arraysæ ¼ç´")
)

export type PositionStore = Schema.Schema.Type<typeof PositionStoreSchema>
export type VelocityStore = Schema.Schema.Type<typeof VelocityStoreSchema>
export type HealthStore = Schema.Schema.Type<typeof HealthStoreSchema>

// SoAæ“ä½œãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
export const SoAOperations = {
  // ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸä½ç½®æ›´æ–°
  updatePositions: (
    positions: PositionStore,
    velocities: VelocityStore,
    deltaTime: number
  ): Effect.Effect<void, never> => Effect.gen(function* () {
    const count = Math.min(positions.count, velocities.count)

    // SIMDæœ€é©åŒ–å¯èƒ½ãªãƒ«ãƒ¼ãƒ—
    // Array.range + Effect.forEach ã«ã‚ˆã‚‹ä¸¦åˆ—SIMDå‡¦ç†
    yield* Effect.forEach(
      Array.range(0, count),
      (i) => Effect.gen(function* () {
        positions.x[i] += velocities.x[i] * deltaTime
        positions.y[i] += velocities.y[i] * deltaTime
        positions.z[i] += velocities.z[i] * deltaTime
      }),
      { concurrency: 'unbounded' } // è¨ˆç®—é›†ç´„çš„å‡¦ç†ã®ä¸¦åˆ—åŒ–
    )
  }),

  // ãƒãƒƒãƒã§ã®è·é›¢è¨ˆç®—
  calculateDistancesBatch: (
    positions1: PositionStore,
    positions2: PositionStore,
    results: Float32Array
  ): Effect.Effect<void, never> => Effect.gen(function* () {
    const count = Math.min(positions1.count, positions2.count, results.length)

    // Array.range + Effect.forEach ã«ã‚ˆã‚‹ä¸¦åˆ—è·é›¢è¨ˆç®—
    yield* Effect.forEach(
      Array.range(0, count),
      (i) => Effect.gen(function* () {
        const dx = positions1.x[i] - positions2.x[i]
        const dy = positions1.y[i] - positions2.y[i]
        const dz = positions1.z[i] - positions2.z[i]

        results[i] = Math.sqrt(dx * dx + dy * dy + dz * dz)
      }),
      { concurrency: 'unbounded' } // CPUé›†ç´„çš„ãªæ•°å­¦è¨ˆç®—ã®ä¸¦åˆ—åŒ–
    )
  }),

  // ç¯„å›²ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–
  findEntitiesInRange: (
    positions: PositionStore,
    centerX: number,
    centerY: number,
    centerZ: number,
    radius: number,
    resultIndices: Uint32Array
  ): Effect.Effect<number, never> => Effect.gen(function* () {
    let resultCount = 0
    const radiusSquared = radius * radius

    // Effect.loop ã«ã‚ˆã‚‹æ¡ä»¶ä»˜ãåå¾©å‡¦ç†ï¼ˆæ—©æœŸçµ‚äº†å¯¾å¿œï¼‰
    let currentIndex = 0

    yield* Effect.loop(
      { index: currentIndex, resultCount },
      ({ index, resultCount }) => index < positions.count && resultCount < resultIndices.length,
      ({ index, resultCount }) => Effect.gen(function* () {
        const dx = positions.x[index] - centerX
        const dy = positions.y[index] - centerY
        const dz = positions.z[index] - centerZ

        const distanceSquared = dx * dx + dy * dy + dz * dz

        const newResultCount = yield* pipe(
          distanceSquared <= radiusSquared,
          Match.boolean({
            onTrue: () => Effect.gen(function* () {
              resultIndices[resultCount] = index
              return resultCount + 1
            }),
            onFalse: () => Effect.succeed(resultCount)
          })
        )

        return { index: index + 1, resultCount: newResultCount }
      })
    ).pipe(Effect.map(({ resultCount }) => resultCount))

    return resultCount
  }),

  // ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªåœ§ç¸®
  compactStore: <T extends { count: number; capacity: number }>(
    store: T & { [K in keyof T]: T[K] extends TypedArray ? T[K] : T[K] }
  ): Effect.Effect<T, never> => Effect.gen(function* () {
    return yield* pipe(
      store.count >= store.capacity * 0.75,
      Match.boolean({
        onTrue: () => Effect.succeed(store), // 75%ä»¥ä¸Šä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯åœ§ç¸®ã—ãªã„
        onFalse: () => Effect.gen(function* () {
          // åœ§ç¸®å‡¦ç†ã‚’ç¶šè¡Œ

          // ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹éƒ¨åˆ†ã®ã¿ã‚’æ–°ã—ã„é…åˆ—ã«ã‚³ãƒ”ãƒ¼
          const newCapacity = Math.max(store.count, Math.floor(store.capacity / 2))

          // TypedArrayã®å„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’åœ§ç¸®
          const compactedStore = { ...store }
          // Record.fromEntries + Effect.forEach ã«ã‚ˆã‚‹å‹å®‰å…¨ãªå¤‰æ›
          yield* Effect.forEach(
            Object.entries(store),
            ([key, value]) => Effect.gen(function* () {
              yield* pipe(
                value instanceof Float32Array || value instanceof Uint32Array,
                Match.boolean({
                  onTrue: () => Effect.gen(function* () {
                    const newArray = new (value.constructor as any)(newCapacity)
                    newArray.set(value.subarray(0, store.count))
                    ;(compactedStore as any)[key] = newArray
                  }),
                  onFalse: () => Effect.unit
                })
              )
            }),
            { concurrency: 'unbounded' }
          )

          ;(compactedStore as any).capacity = newCapacity

          yield* Effect.logDebug(`Store compacted: ${store.capacity} -> ${newCapacity} (${store.count} active)`)
          return compactedStore
        })
      })
    )
  })
}

// ECS ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿ã®å‹å®‰å…¨ãªå®šç¾©
export const EntityIdSchema = Schema.String.pipe(
  Schema.pattern(/^entity-[a-f0-9-]+$/),
  Schema.brand("EntityId")
)

export const EntityDataSchema = Schema.Struct({
  id: EntityIdSchema,
  position: Schema.Struct({
    x: Schema.Number,
    y: Schema.Number,
    z: Schema.Number
  }),
  velocity: Schema.optional(Schema.Struct({
    x: Schema.Number,
    y: Schema.Number,
    z: Schema.Number
  })),
  health: Schema.optional(Schema.Struct({
    current: Schema.Number.pipe(Schema.nonnegative()),
    maximum: Schema.Number.pipe(Schema.positive())
  }))
}).pipe(
  Schema.filter((entity) => {
    return !entity.health || entity.health.current <= entity.health.maximum
  }, {
    message: () => "ç¾åœ¨ã®ãƒ˜ãƒ«ã‚¹ãŒæœ€å¤§ãƒ˜ãƒ«ã‚¹ã‚’è¶…ãˆã¦ã„ã¾ã™"
  }),
  Schema.identifier("EntityData"),
  Schema.description("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®åˆæœŸåŒ–ãƒ‡ãƒ¼ã‚¿")
)

export const SystemErrorSchema = Schema.TaggedError("SystemError")({
  operation: Schema.String,
  entityId: Schema.optional(EntityIdSchema),
  reason: Schema.String,
  timestamp: Schema.Number.pipe(Schema.brand("Timestamp"))
})

export type EntityId = Schema.Schema.Type<typeof EntityIdSchema>
export type EntityData = Schema.Schema.Type<typeof EntityDataSchema>
export type SystemError = Schema.Schema.Type<typeof SystemErrorSchema>

// SoA ECSã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ä¾‹
export interface SoAEntitySystem {
  private positions: PositionStore
  private velocities: VelocityStore
  private healths: HealthStore
  private entityIndices: Map<EntityId, number>

  constructor(initialCapacity: number = 10000) {
    this.positions = {
      x: new Float32Array(initialCapacity),
      y: new Float32Array(initialCapacity),
      z: new Float32Array(initialCapacity),
      count: 0,
      capacity: initialCapacity
    }

    this.velocities = {
      x: new Float32Array(initialCapacity),
      y: new Float32Array(initialCapacity),
      z: new Float32Array(initialCapacity),
      count: 0,
      capacity: initialCapacity
    }

    this.healths = {
      current: new Float32Array(initialCapacity),
      maximum: new Float32Array(initialCapacity),
      count: 0,
      capacity: initialCapacity
    }
  }

  addEntity = (entityId: EntityId, initialData: EntityData): Effect.Effect<number, SystemError> =>
    Effect.gen(function* () {
      yield* pipe(
        this.positions.count >= this.positions.capacity,
        Match.boolean({
          onTrue: () => this.expandCapacity(),
          onFalse: () => Effect.unit
        })
      )

      const index = this.positions.count

      // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¨­å®š
      this.positions.x[index] = initialData.position.x
      this.positions.y[index] = initialData.position.y
      this.positions.z[index] = initialData.position.z

      pipe(
        initialData.velocity,
        Option.fromNullable,
        Option.match({
          onNone: () => {},
          onSome: (velocity) => {
            this.velocities.x[index] = velocity.x
            this.velocities.y[index] = velocity.y
            this.velocities.z[index] = velocity.z
            this.velocities.count++
          }
        })
      )

      pipe(
        initialData.health,
        Option.fromNullable,
        Option.match({
          onNone: () => {},
          onSome: (health) => {
            this.healths.current[index] = health.current
            this.healths.maximum[index] = health.maximum
            this.healths.count++
          }
        })
      )

      this.entityIndices.set(entityId, index)
      this.positions.count++

      return index
    })

  updateSystem = (deltaTime: number): Effect.Effect<void, SystemError> =>
    Effect.gen(function* () {
      // ç‰©ç†æ›´æ–°ï¼ˆä½ç½® += é€Ÿåº¦ * æ™‚é–“ï¼‰
      yield* SoAOperations.updatePositions(this.positions, this.velocities, deltaTime)

      // ãƒ˜ãƒ«ã‚¹å›å¾©ã®å‡¦ç†
      yield* this.processHealthRegeneration(deltaTime)

      // è¡çªæ¤œå‡ºã®æœ€é©åŒ–å‡¦ç†
      yield* this.processCollisionDetection()
    })

  private expandCapacity = (): Effect.Effect<void, SystemError> =>
    Effect.gen(function* () {
      const newCapacity = this.positions.capacity * 2

      // å„TypedArrayã‚’æ‹¡å¼µ
      this.positions = yield* this.expandTypedArrayStore(this.positions, newCapacity)
      this.velocities = yield* this.expandTypedArrayStore(this.velocities, newCapacity)
      this.healths = yield* this.expandTypedArrayStore(this.healths, newCapacity)

      yield* Effect.logInfo(`Entity system capacity expanded to ${newCapacity}`)
    })

  private expandTypedArrayStore = <T extends { capacity: number }>(
    store: T,
    newCapacity: number
  ): Effect.Effect<T, SystemError> =>
    Effect.gen(function* () {
      const expandedStore = { ...store }

      // Record.fromEntries + Effect.forEach ã«ã‚ˆã‚‹ã‚¿ã‚¤ãƒ—é…åˆ—æ‹¡å¼µ
      yield* Effect.forEach(
        Object.entries(store),
        ([key, value]) => Effect.gen(function* () {
          if (value instanceof Float32Array || value instanceof Uint32Array) {
            const newArray = new (value.constructor as any)(newCapacity)
            newArray.set(value)
            ;(expandedStore as any)[key] = newArray
          }
        }),
        { concurrency: 3 } // I/Oé›†ç´„çš„ã§ãªã„ãŸã‚åˆ¶é™ä»˜ãä¸¦åˆ—
      )

      ;(expandedStore as any).capacity = newCapacity
      return expandedStore
    })
}
```

### Step 3: Worker Poolæœ€é©åŒ–

CPUé›†ç´„çš„å‡¦ç†ã®ä¸¦åˆ—åŒ–ï¼š

```typescript
// src/performance/worker-pool.ts
import { Effect, Context, Layer, Queue } from 'effect'

// Workerã‚¿ã‚¹ã‚¯ã®å‹å®‰å…¨ãªå®šç¾©
export const WorkerTaskTypeSchema = Schema.Literal('mesh-generation', 'pathfinding', 'physics', 'lighting')
export const WorkerTaskPrioritySchema = Schema.Number.pipe(
  Schema.int(),
  Schema.between(0, 10),
  Schema.brand('TaskPriority')
)

export const WorkerTaskIdSchema = Schema.String.pipe(
  Schema.pattern(/^task-[a-zA-Z0-9-]+$/),
  Schema.brand('WorkerTaskId')
)

export const WorkerIdSchema = Schema.String.pipe(Schema.pattern(/^worker-[a-zA-Z0-9-]+$/), Schema.brand('WorkerId'))

// å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚­ãƒ¼ãƒ
export const MeshGenerationDataSchema = Schema.Struct({
  chunkCoords: Schema.Array(Schema.Number).pipe(Schema.minItems(3), Schema.maxItems(3)),
  blockData: Schema.instanceOf(Uint16Array),
  lightingData: Schema.optional(Schema.instanceOf(Uint8Array)),
})

export const PathfindingDataSchema = Schema.Struct({
  start: Schema.Array(Schema.Number).pipe(Schema.minItems(3), Schema.maxItems(3)),
  end: Schema.Array(Schema.Number).pipe(Schema.minItems(3), Schema.maxItems(3)),
  obstacles: Schema.Array(Schema.Array(Schema.Number)),
  maxDistance: Schema.Number.pipe(Schema.positive()),
})

// ã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã®TaggedUnion
export const WorkerTaskDataSchema = Schema.TaggedUnion('type', {
  'mesh-generation': Schema.Struct({
    type: Schema.Literal('mesh-generation'),
    data: MeshGenerationDataSchema,
  }),
  pathfinding: Schema.Struct({
    type: Schema.Literal('pathfinding'),
    data: PathfindingDataSchema,
  }),
  physics: Schema.Struct({
    type: Schema.Literal('physics'),
    data: Schema.Record(Schema.String, Schema.Unknown), // ç‰©ç†è¨ˆç®—ç”¨ã®æ±ç”¨ãƒ‡ãƒ¼ã‚¿
  }),
  lighting: Schema.Struct({
    type: Schema.Literal('lighting'),
    data: Schema.Record(Schema.String, Schema.Unknown), // ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°è¨ˆç®—ç”¨ã®æ±ç”¨ãƒ‡ãƒ¼ã‚¿
  }),
})

export const WorkerTaskSchema = Schema.Struct({
  id: WorkerTaskIdSchema,
  type: WorkerTaskTypeSchema,
  data: WorkerTaskDataSchema,
  priority: WorkerTaskPrioritySchema,
  timeout: Schema.Number.pipe(Schema.positive(), Schema.brand('TaskTimeout')),
  retryCount: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('TaskRetryCount')),
  createdAt: Schema.Number.pipe(Schema.positive(), Schema.brand('Timestamp')),
}).pipe(Schema.identifier('WorkerTask'), Schema.description('WebWorkerã§å®Ÿè¡Œã•ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ã®å‹å®‰å…¨ãªå®šç¾©'))

export type WorkerTask = Schema.Schema.Type<typeof WorkerTaskSchema>
export type WorkerTaskType = Schema.Schema.Type<typeof WorkerTaskTypeSchema>
export type WorkerTaskData = Schema.Schema.Type<typeof WorkerTaskDataSchema>

// Workerçµæœã®å‹å®‰å…¨ãªå®šç¾©
export const WorkerResultSchema = Schema.Struct({
  taskId: WorkerTaskIdSchema,
  success: Schema.Boolean,
  result: Schema.optional(Schema.Unknown),
  error: Schema.optional(Schema.String.pipe(Schema.maxLength(1000), Schema.brand('ErrorMessage'))),
  executionTime: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('ExecutionTime')),
  workerId: WorkerIdSchema,
  completedAt: Schema.Number.pipe(Schema.positive(), Schema.brand('Timestamp')),
  memoryUsage: Schema.optional(Schema.Number.pipe(Schema.nonnegative(), Schema.brand('MemoryUsage'))),
}).pipe(Schema.identifier('WorkerResult'), Schema.description('WebWorkerã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœã®å‹å®‰å…¨ãªå®šç¾©'))

export type WorkerResult = Schema.Schema.Type<typeof WorkerResultSchema>

// Worker Pool é–¢é€£ã®å‹å®šç¾©
export const PoolStatusSchema = Schema.Struct({
  totalWorkers: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('WorkerCount')),
  availableWorkers: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('AvailableWorkerCount')),
  busyWorkers: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('BusyWorkerCount')),
  pendingTasks: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('PendingTaskCount')),
  statistics: Schema.Struct({
    totalTasks: Schema.Number.pipe(Schema.int(), Schema.nonnegative()),
    completedTasks: Schema.Number.pipe(Schema.int(), Schema.nonnegative()),
    failedTasks: Schema.Number.pipe(Schema.int(), Schema.nonnegative()),
    averageExecutionTime: Schema.Number.pipe(Schema.nonnegative()),
    workerUtilization: Schema.Record(Schema.String, Schema.Number),
  }),
}).pipe(
  Schema.filter(
    (status) => {
      return (
        status.totalWorkers === status.availableWorkers + status.busyWorkers &&
        status.statistics.totalTasks === status.statistics.completedTasks + status.statistics.failedTasks
      )
    },
    {
      message: () => 'PoolStatus ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ',
    }
  ),
  Schema.identifier('PoolStatus'),
  Schema.description('ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«ã®çŠ¶æ…‹æƒ…å ±')
)

export const WorkerErrorSchema = Schema.TaggedError('WorkerError')({
  operation: Schema.String,
  workerId: Schema.optional(WorkerIdSchema),
  taskId: Schema.optional(WorkerTaskIdSchema),
  reason: Schema.String,
  timestamp: Schema.Number.pipe(Schema.brand('Timestamp')),
})

export type PoolStatus = Schema.Schema.Type<typeof PoolStatusSchema>
export type WorkerError = Schema.Schema.Type<typeof WorkerErrorSchema>

// Worker Pool ã‚µãƒ¼ãƒ“ã‚¹
export interface WorkerPoolService {
  readonly submitTask: (task: WorkerTask) => Effect.Effect<WorkerResult, WorkerError>
  readonly submitBatch: (tasks: ReadonlyArray<WorkerTask>) => Effect.Effect<ReadonlyArray<WorkerResult>, WorkerError>
  readonly getPoolStatus: Effect.Effect<PoolStatus, never>
  readonly adjustPoolSize: (newSize: number & Brand.Brand<'WorkerCount'>) => Effect.Effect<void, WorkerError>
  readonly shutdown: Effect.Effect<void, never>
  readonly validateTask: (task: unknown) => Effect.Effect<WorkerTask, ParseError>
  readonly validateResult: (result: unknown) => Effect.Effect<WorkerResult, ParseError>
}

export const WorkerPoolService = Context.GenericTag<WorkerPoolService>('@minecraft/WorkerPoolService')

// Worker Pool ã®å®Ÿè£…
const makeWorkerPoolService = Effect.gen(function* () {
  // Workerç®¡ç†
  const workers = new Map<string, Worker>()
  const availableWorkers = yield* Queue.bounded<string>(10)
  const pendingTasks = yield* Queue.unbounded<WorkerTask>()
  const taskResults = new Map<string, WorkerResult>()

  // çµ±è¨ˆæƒ…å ±
  const stats = {
    totalTasks: 0,
    completedTasks: 0,
    failedTasks: 0,
    averageExecutionTime: 0,
    workerUtilization: new Map<string, number>(),
  }

  // Workerã®ä½œæˆ
  const createWorker = (workerId: string, workerType: string): Effect.Effect<Worker, WorkerError> =>
    Effect.gen(function* () {
      const workerScript = getWorkerScript(workerType)

      const worker = new Worker(workerScript, {
        type: 'module',
        name: workerId,
      })

      // WorkeråˆæœŸåŒ–ã®å¾…æ©Ÿ
      yield* Effect.async<void, WorkerError>((resolve) => {
        const handleMessage = (event: MessageEvent) => {
          if (event.data.type === 'ready') {
            worker.removeEventListener('message', handleMessage)
            resolve(Effect.succeed(void 0))
          }
        }

        const handleError = (error: ErrorEvent) => {
          worker.removeEventListener('error', handleError)
          resolve(
            Effect.fail(
              new WorkerError({
                operation: 'createWorker',
                workerId,
                reason: error.message,
              })
            )
          )
        }

        worker.addEventListener('message', handleMessage)
        worker.addEventListener('error', handleError)

        // åˆæœŸåŒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
        worker.postMessage({ type: 'initialize', config: getWorkerConfig() })
      })

      workers.set(workerId, worker)
      yield* Queue.offer(availableWorkers, workerId)

      yield* Effect.logInfo(`Worker created: ${workerId} (${workerType})`)
      return worker
    })

  // ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
  const executeTask = (task: WorkerTask): Effect.Effect<WorkerResult, WorkerError> =>
    Effect.gen(function* () {
      // åˆ©ç”¨å¯èƒ½ãªWorkerã‚’å–å¾—ï¼ˆå„ªå…ˆåº¦é †ï¼‰
      const workerId = yield* Queue.take(availableWorkers)
      const worker = workers.get(workerId)

      yield* pipe(
        worker,
        Option.fromNullable,
        Option.match({
          onNone: () =>
            Effect.gen(function* () {
              yield* Queue.offer(availableWorkers, workerId) // Workerã‚’æˆ»ã™
              return yield* Effect.fail(
                new WorkerError({
                  operation: 'executeTask',
                  workerId,
                  reason: 'Worker not found',
                })
              )
            }),
          onSome: () => Effect.unit,
        })
      )

      const startTime = performance.now()

      // ã‚¿ã‚¹ã‚¯ã‚’Workerã«é€ä¿¡ã—ã€çµæœã‚’å¾…æ©Ÿ
      const result = yield* Effect.async<WorkerResult, WorkerError>((resolve) => {
        const timeout = setTimeout(() => {
          resolve(
            Effect.fail(
              new WorkerError({
                operation: 'executeTask',
                workerId,
                reason: `Task timeout after ${task.timeout}ms`,
                taskId: task.id,
              })
            )
          )
        }, task.timeout)

        const handleMessage = (event: MessageEvent) => {
          if (event.data.taskId === task.id) {
            clearTimeout(timeout)
            worker.removeEventListener('message', handleMessage)

            const executionTime = performance.now() - startTime
            const result: WorkerResult = {
              ...event.data,
              executionTime,
              workerId,
            }

            resolve(Effect.succeed(result))
          }
        }

        const handleError = (error: ErrorEvent) => {
          clearTimeout(timeout)
          worker.removeEventListener('error', handleError)
          resolve(
            Effect.fail(
              new WorkerError({
                operation: 'executeTask',
                workerId,
                reason: error.message,
                taskId: task.id,
              })
            )
          )
        }

        worker.addEventListener('message', handleMessage)
        worker.addEventListener('error', handleError)

        // ã‚¿ã‚¹ã‚¯ã‚’é€ä¿¡
        worker.postMessage({
          type: 'task',
          ...task,
        })
      })

      // Workerã‚’åˆ©ç”¨å¯èƒ½ãƒ—ãƒ¼ãƒ«ã«æˆ»ã™
      yield* Queue.offer(availableWorkers, workerId)

      // çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
      stats.completedTasks++
      stats.totalTasks++

      const currentAvg = stats.averageExecutionTime
      const count = stats.completedTasks
      stats.averageExecutionTime = (currentAvg * (count - 1) + result.executionTime) / count

      // Workerã®åˆ©ç”¨ç‡ã‚’æ›´æ–°
      const currentUtilization = stats.workerUtilization.get(workerId) || 0
      stats.workerUtilization.set(workerId, currentUtilization + result.executionTime)

      return result
    })

  return WorkerPoolService.of({
    submitTask: (task) =>
      Effect.gen(function* () {
        stats.totalTasks++

        // é«˜å„ªå…ˆåº¦ã‚¿ã‚¹ã‚¯ã®å ´åˆã¯å³åº§ã«å®Ÿè¡Œ
        return yield* pipe(
          task.priority <= 2,
          Match.boolean({
            onTrue: () => executeTask(task),
            onFalse: () =>
              Effect.gen(function* () {
                // é€šå¸¸ã®å„ªå…ˆåº¦ã®å ´åˆã¯ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
                yield* Queue.offer(pendingTasks, task)

                // ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’å–å¾—ã—ã¦å®Ÿè¡Œ
                const queuedTask = yield* Queue.take(pendingTasks)
                return yield* executeTask(queuedTask)
              }),
          })
        )
      }),

    submitBatch: (tasks) =>
      Effect.gen(function* () {
        // å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        const sortedTasks = [...tasks].sort((a, b) => a.priority - b.priority)

        // ä¸¦åˆ—å®Ÿè¡Œï¼ˆåˆ©ç”¨å¯èƒ½ãªWorkeræ•°ã«åˆ¶é™ï¼‰
        const results = yield* Effect.all(
          sortedTasks.map((task) => executeTask(task)),
          { concurrency: workers.size, batching: true }
        )

        return results
      }),

    getPoolStatus: Effect.gen(function* () {
      const availableCount = yield* Queue.size(availableWorkers)
      const pendingCount = yield* Queue.size(pendingTasks)

      return {
        totalWorkers: workers.size,
        availableWorkers: availableCount,
        busyWorkers: workers.size - availableCount,
        pendingTasks: pendingCount,
        statistics: {
          ...stats,
          workerUtilization: Object.fromEntries(stats.workerUtilization),
        },
      }
    }),

    adjustPoolSize: (newSize) =>
      Effect.gen(function* () {
        const currentSize = workers.size

        yield* pipe(
          { newSize, currentSize },
          Match.value({
            when: ({ newSize, currentSize }) => newSize > currentSize,
            then: ({ newSize, currentSize }) =>
              Effect.gen(function* () {
                // Workerã‚’è¿½åŠ 
                const addCount = newSize - currentSize
                yield* Effect.forEach(
                  Array.from({ length: addCount }, (_, i) => `worker-${currentSize + i}`),
                  (workerId) => createWorker(workerId, 'general'),
                  { concurrency: 3 }
                )
              }),
          }),
          Match.when(
            ({ newSize, currentSize }) => newSize < currentSize,
            ({ newSize, currentSize }) =>
              Effect.gen(function* () {
                // Workerã‚’å‰Šé™¤
                const removeCount = currentSize - newSize
                const workersToRemove = Array.from(workers.keys()).slice(-removeCount)

                yield* Effect.forEach(
                  workersToRemove,
                  (workerId) =>
                    Effect.gen(function* () {
                      const worker = workers.get(workerId)
                      yield* pipe(
                        worker,
                        Option.fromNullable,
                        Option.match({
                          onNone: () => Effect.unit,
                          onSome: (w) =>
                            Effect.gen(function* () {
                              w.terminate()
                              workers.delete(workerId)
                              yield* Effect.logInfo(`Worker terminated: ${workerId}`)
                            }),
                        })
                      )
                    }),
                  { concurrency: 'unbounded' }
                )
              })
          ),
          Match.orElse(() => Effect.unit)
        )

        yield* Effect.logInfo(`Worker pool size adjusted: ${currentSize} -> ${newSize}`)
      }),

    shutdown: Effect.gen(function* () {
      // ã™ã¹ã¦ã®Workerã‚’çµ‚äº†
      yield* Effect.forEach(Array.from(workers.values()), (worker) => Effect.sync(() => worker.terminate()), {
        concurrency: 'unbounded',
      })

      workers.clear()
      yield* Effect.logInfo('Worker pool shutdown completed')
    }),
  })
})

export const WorkerPoolServiceLive = Layer.effect(WorkerPoolService, makeWorkerPoolService)
```

### Step 4: ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«æœ€é©åŒ–

GCåœ§åŠ›ã®è»½æ¸›ã¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†åˆ©ç”¨ï¼š

```typescript
// src/performance/memory-pool.ts
import { Effect, Context, Layer, Ref } from 'effect'

// ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã®å‹å®‰å…¨ãªå®šç¾©
export const MemoryPoolStatsSchema = Schema.Struct({
  available: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('AvailableCount')),
  inUse: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('InUseCount')),
  total: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('TotalCount')),
  utilizationRate: Schema.Number.pipe(Schema.between(0, 1), Schema.brand('UtilizationRate')),
  peakUsage: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('PeakUsage')),
  allocationCount: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('AllocationCount')),
  releaseCount: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('ReleaseCount')),
}).pipe(
  Schema.filter(
    (stats) => {
      return (
        stats.available + stats.inUse === stats.total &&
        stats.utilizationRate === (stats.total > 0 ? stats.inUse / stats.total : 0) &&
        stats.allocationCount >= stats.releaseCount
      )
    },
    {
      message: () => 'MemoryPoolStats ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ',
    }
  ),
  Schema.identifier('MemoryPoolStats'),
  Schema.description('ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã®çµ±è¨ˆæƒ…å ±')
)

export const MemoryPoolConfigSchema = <A, I, R>(itemSchema: Schema.Schema<A, I, R>) =>
  Schema.Struct({
    name: Schema.String.pipe(Schema.minLength(1), Schema.maxLength(50), Schema.brand('PoolName')),
    factory: Schema.Function.pipe(Schema.description('ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°')),
    reset: Schema.Function.pipe(Schema.description('ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆé–¢æ•°')),
    validate: Schema.optional(Schema.Function.pipe(Schema.description('ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œè¨¼é–¢æ•°'))),
    initialSize: Schema.optional(Schema.Number.pipe(Schema.int(), Schema.positive(), Schema.brand('InitialSize'))),
    maxSize: Schema.optional(Schema.Number.pipe(Schema.int(), Schema.positive(), Schema.brand('MaxSize'))),
    enableMetrics: Schema.optional(Schema.Boolean),
    warnOnLeak: Schema.optional(Schema.Boolean),
  }).pipe(
    Schema.filter(
      (config) => {
        return !config.maxSize || !config.initialSize || config.initialSize <= config.maxSize
      },
      {
        message: () => 'initialSize ã¯ maxSize ä»¥ä¸‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™',
      }
    ),
    Schema.identifier('MemoryPoolConfig'),
    Schema.description('ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«è¨­å®šã®å‹å®‰å…¨ãªå®šç¾©')
  )

// ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®å®šç¾©
export interface MemoryPool<T> {
  readonly acquire: () => Effect.Effect<T, never, never>
  readonly release: (item: T) => Effect.Effect<void, never, never>
  readonly getStats: () => Effect.Effect<MemoryPoolStats, never, never>
  readonly preAllocate: (count: number) => Effect.Effect<void, never, never>
  readonly clear: () => Effect.Effect<void, never, never>
  readonly validateIntegrity: () => Effect.Effect<boolean, never, never>
}

export type MemoryPoolStats = Schema.Schema.Type<typeof MemoryPoolStatsSchema>
export type MemoryPoolConfig<T> = {
  readonly name: string & Brand.Brand<'PoolName'>
  readonly factory: () => T
  readonly reset: (item: T) => void
  readonly validate?: (item: T) => boolean
  readonly initialSize?: number & Brand.Brand<'InitialSize'>
  readonly maxSize?: number & Brand.Brand<'MaxSize'>
  readonly enableMetrics?: boolean
  readonly warnOnLeak?: boolean
}

// ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã®ä½œæˆé–¢æ•°ï¼ˆå‹å®‰å…¨ï¼‰
export const makeMemoryPool = <A, I, R>(
  itemSchema: Schema.Schema<A, I, R>,
  config: MemoryPoolConfig<A>
): Effect.Effect<MemoryPool<A>, never, never> =>
  Effect.gen(function* () {
    const { factory, reset, initialSize = 10, maxSize = 1000 } = config

    // çŠ¶æ…‹ç®¡ç†ç”¨ã®Ref
    const available = yield* Ref.make<T[]>([])
    const inUse = yield* Ref.make(new Set<T>())

    // åˆæœŸãƒ—ãƒ¼ãƒ«ã‚’ä½œæˆ
    const initialItems: T[] = []
    // Array.makeBy + Effect.succeed ã«ã‚ˆã‚‹åˆæœŸåŒ–é…åˆ—ç”Ÿæˆ
    const initialItems = Array.makeBy(initialSize, () => factory())
    yield* Ref.set(available, initialItems)

    const acquire = (): Effect.Effect<T, never, never> =>
      Effect.gen(function* () {
        const availableItems = yield* Ref.get(available)
        let item: T

        if (availableItems.length > 0) {
          const [first, ...rest] = availableItems
          item = first
          yield* Ref.set(available, rest)
        } else {
          item = factory()
          yield* Effect.logDebug('Memory pool: created new item (pool exhausted)')
        }

        yield* Ref.update(inUse, (set) => new Set(set).add(item))
        return item
      })

    const release = (item: T): Effect.Effect<void, never, never> =>
      Effect.gen(function* () {
        const currentInUse = yield* Ref.get(inUse)
        if (!currentInUse.has(item)) {
          yield* Effect.logWarning('Memory pool: attempted to release item not in use')
          return
        }

        yield* Ref.update(inUse, (set) => {
          const newSet = new Set(set)
          newSet.delete(item)
          return newSet
        })

        const currentAvailable = yield* Ref.get(available)
        if (currentAvailable.length < maxSize) {
          yield* Ref.update(available, (items) => [...items, item])
        } else {
          // ãƒ—ãƒ¼ãƒ«ãŒæº€æ¯ã®å ´åˆã¯GCã«ä»»ã›ã‚‹
          yield* Effect.logDebug('Memory pool: discarded item (pool full)')
        }
      })

    const getStats = (): Effect.Effect<MemoryPoolStats, never, never> =>
      Effect.gen(function* () {
        const availableItems = yield* Ref.get(available)
        const inUseItems = yield* Ref.get(inUse)
        return {
          available: availableItems.length,
          inUse: inUseItems.size,
          total: availableItems.length + inUseItems.size,
        }
      })

    return {
      acquire,
      release,
      getStats,
    }
  })

// ã‚²ãƒ¼ãƒ å›ºæœ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‹å®šç¾©
export const Vector3Schema = Schema.Struct({
  x: Schema.Number,
  y: Schema.Number,
  z: Schema.Number,
}).pipe(Schema.identifier('Vector3'), Schema.description('3æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«'))

export const EntitySchema = Schema.Struct({
  id: EntityIdSchema,
  components: Schema.instanceOf(Map),
  active: Schema.Boolean,
  lastUpdateTime: Schema.optional(Schema.Number.pipe(Schema.brand('Timestamp'))),
}).pipe(Schema.identifier('Entity'), Schema.description('ã‚²ãƒ¼ãƒ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£'))

export const ParticleSchema = Schema.Struct({
  position: Vector3Schema,
  velocity: Vector3Schema,
  life: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('ParticleLife')),
  maxLife: Schema.Number.pipe(Schema.positive(), Schema.brand('ParticleMaxLife')),
  size: Schema.Number.pipe(Schema.positive(), Schema.brand('ParticleSize')),
  color: Schema.Struct({
    r: Schema.Number.pipe(Schema.between(0, 1)),
    g: Schema.Number.pipe(Schema.between(0, 1)),
    b: Schema.Number.pipe(Schema.between(0, 1)),
    a: Schema.Number.pipe(Schema.between(0, 1)),
  }),
}).pipe(
  Schema.filter((particle) => particle.life <= particle.maxLife, {
    message: () => 'ãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«ã®lifeã¯maxLifeä»¥ä¸‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™',
  }),
  Schema.identifier('Particle'),
  Schema.description('ãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«åŠ¹æœ')
)

export const MeshDataSchema = Schema.Struct({
  vertices: Schema.instanceOf(Float32Array),
  indices: Schema.instanceOf(Uint32Array),
  normals: Schema.instanceOf(Float32Array),
  uvs: Schema.instanceOf(Float32Array),
  vertexCount: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('VertexCount')),
  indexCount: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('IndexCount')),
}).pipe(
  Schema.filter(
    (mesh) => {
      const expectedVertexBytes = mesh.vertexCount * 3 * 4 // 3 floats per vertex
      const expectedIndexBytes = mesh.indexCount * 4 // 1 uint32 per index
      return mesh.vertices.byteLength >= expectedVertexBytes && mesh.indices.byteLength >= expectedIndexBytes
    },
    {
      message: () => 'ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã®é…åˆ—ã‚µã‚¤ã‚ºã¨ã‚«ã‚¦ãƒ³ãƒˆãŒä¸€è‡´ã—ã¾ã›ã‚“',
    }
  ),
  Schema.identifier('MeshData'),
  Schema.description('3Dãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿')
)

export const GlobalPoolStatsSchema = Schema.Struct({
  vector3: MemoryPoolStatsSchema,
  entity: MemoryPoolStatsSchema,
  particle: MemoryPoolStatsSchema,
  meshData: MemoryPoolStatsSchema,
  totalInUse: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('TotalInUse')),
  totalAvailable: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('TotalAvailable')),
  overallUtilization: Schema.Number.pipe(Schema.between(0, 1), Schema.brand('OverallUtilization')),
}).pipe(Schema.identifier('GlobalPoolStats'), Schema.description('å…¨ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã®çµ±è¨ˆæƒ…å ±'))

export type Vector3 = Schema.Schema.Type<typeof Vector3Schema>
export type Entity = Schema.Schema.Type<typeof EntitySchema>
export type Particle = Schema.Schema.Type<typeof ParticleSchema>
export type MeshData = Schema.Schema.Type<typeof MeshDataSchema>
export type GlobalPoolStats = Schema.Schema.Type<typeof GlobalPoolStatsSchema>

// ã‚²ãƒ¼ãƒ å›ºæœ‰ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ¼ãƒ«
export interface MemoryPoolService {
  readonly vector3Pool: MemoryPool<Vector3>
  readonly entityPool: MemoryPool<Entity>
  readonly particlePool: MemoryPool<Particle>
  readonly meshDataPool: MemoryPool<MeshData>
  readonly getGlobalStats: Effect.Effect<GlobalPoolStats, never>
  readonly optimizeAllPools: Effect.Effect<void, never>
  readonly validateAllPools: Effect.Effect<boolean, never>
  readonly clearAllPools: Effect.Effect<void, never>
}

export const MemoryPoolService = Context.GenericTag<MemoryPoolService>('@minecraft/MemoryPoolService')

// Vector3ãƒ—ãƒ¼ãƒ«ï¼ˆé »ç¹ã«ä½¿ç”¨ã•ã‚Œã‚‹ï¼‰
const createVector3Pool = () =>
  makeMemoryPool(Vector3Schema, {
    name: 'vector3-pool' as any,
    factory: () => ({ x: 0, y: 0, z: 0 }),
    reset: (v) => {
      v.x = 0
      v.y = 0
      v.z = 0
    },
    validate: (v) => typeof v.x === 'number' && typeof v.y === 'number' && typeof v.z === 'number',
    initialSize: 100 as any,
    maxSize: 10000 as any,
    enableMetrics: true,
    warnOnLeak: true,
  })

// ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ—ãƒ¼ãƒ«
const createEntityPool = () =>
  makeMemoryPool(EntitySchema, {
    name: 'entity-pool' as any,
    factory: () => ({
      id: '' as any,
      components: new Map(),
      active: false,
    }),
    reset: (entity) => {
      entity.id = '' as any
      entity.components.clear()
      entity.active = false
      entity.lastUpdateTime = undefined
    },
    validate: (entity) => typeof entity.id === 'string' && entity.components instanceof Map,
    initialSize: 50 as any,
    maxSize: 5000 as any,
    enableMetrics: true,
    warnOnLeak: true,
  })

// ãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«ãƒ—ãƒ¼ãƒ«
const createParticlePool = () =>
  makeMemoryPool(ParticleSchema, {
    name: 'particle-pool' as any,
    factory: () => ({
      position: { x: 0, y: 0, z: 0 },
      velocity: { x: 0, y: 0, z: 0 },
      life: 0 as any,
      maxLife: 1 as any, // positiveå€¤ãŒå¿…è¦
      size: 1 as any,
      color: { r: 1, g: 1, b: 1, a: 1 },
    }),
    reset: (particle) => {
      particle.position.x = particle.position.y = particle.position.z = 0
      particle.velocity.x = particle.velocity.y = particle.velocity.z = 0
      particle.life = 0 as any
      particle.maxLife = 1 as any
      particle.size = 1 as any
      particle.color.r = particle.color.g = particle.color.b = particle.color.a = 1
    },
    validate: (particle) => particle.life <= particle.maxLife && particle.size > 0,
    initialSize: 200 as any,
    maxSize: 20000 as any,
    enableMetrics: true,
    warnOnLeak: true,
  })

// ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¼ãƒ«
const createMeshDataPool = () =>
  makeMemoryPool(MeshDataSchema, {
    name: 'mesh-data-pool' as any,
    factory: () => ({
      vertices: new Float32Array(0),
      indices: new Uint32Array(0),
      normals: new Float32Array(0),
      uvs: new Float32Array(0),
      vertexCount: 0 as any,
      indexCount: 0 as any,
    }),
    reset: (meshData) => {
      // TypedArrayã¯å†åˆ©ç”¨ã®ãŸã‚ã«ã‚¯ãƒªã‚¢
      meshData.vertices.fill(0)
      meshData.indices.fill(0)
      meshData.normals.fill(0)
      meshData.uvs.fill(0)
      meshData.vertexCount = 0 as any
      meshData.indexCount = 0 as any
    },
    validate: (meshData) => {
      const expectedVertexBytes = meshData.vertexCount * 3 * 4
      const expectedIndexBytes = meshData.indexCount * 4
      return meshData.vertices.byteLength >= expectedVertexBytes && meshData.indices.byteLength >= expectedIndexBytes
    },
    initialSize: 10 as any,
    maxSize: 1000 as any,
    enableMetrics: true,
    warnOnLeak: true,
  })

// ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚µãƒ¼ãƒ“ã‚¹ã®å®Ÿè£…
const makeMemoryPoolService = Effect.gen(function* () {
  const vector3Pool = createVector3Pool()
  const entityPool = createEntityPool()
  const particlePool = createParticlePool()
  const meshDataPool = createMeshDataPool()

  return MemoryPoolService.of({
    vector3Pool,
    entityPool,
    particlePool,
    meshDataPool,

    getGlobalStats: Effect.gen(function* () {
      const [vector3Stats, entityStats, particleStats, meshStats] = yield* Effect.all([
        vector3Pool.getStats(),
        entityPool.getStats(),
        particlePool.getStats(),
        meshDataPool.getStats(),
      ])

      return {
        vector3: vector3Stats,
        entity: entityStats,
        particle: particleStats,
        meshData: meshStats,
        totalInUse: vector3Stats.inUse + entityStats.inUse + particleStats.inUse + meshStats.inUse,
        totalAvailable: vector3Stats.available + entityStats.available + particleStats.available + meshStats.available,
      }
    }),

    optimizeAllPools: Effect.gen(function* () {
      const stats = yield* MemoryPoolService.getGlobalStats()

      // ä½¿ç”¨ç‡ãŒä½ã„ãƒ—ãƒ¼ãƒ«ã‚’ç¸®å°
      if (stats.vector3.available > stats.vector3.inUse * 3) {
        yield* Effect.logInfo('Optimizing Vector3 pool (high unused ratio)')
        // å®Ÿéš›ã®æœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã“ã“ã«å®Ÿè£…
      }

      if (stats.particle.available > stats.particle.inUse * 2) {
        yield* Effect.logInfo('Optimizing Particle pool (high unused ratio)')
      }

      yield* Effect.logInfo('Memory pool optimization completed')
    }),
  })
})

export const MemoryPoolServiceLive = Layer.effect(MemoryPoolService, makeMemoryPoolService)

// ä½¿ç”¨ä¾‹: ã‚¹ã‚³ãƒ¼ãƒ—ä»˜ããƒªã‚½ãƒ¼ã‚¹ç®¡ç†ï¼ˆå‹å®‰å…¨ï¼‰
export const withPooledVector3 = <A, E, R>(
  operation: (vector: Vector3) => Effect.Effect<A, E, R>
): Effect.Effect<A, E, R | MemoryPoolService> =>
  Effect.gen(function* () {
    const pools = yield* MemoryPoolService
    const vector = yield* pools.vector3Pool.acquire()

    try {
      const result = yield* operation(vector)
      return result
    } finally {
      yield* pools.vector3Pool.release(vector)
    }
  })

// ãƒãƒƒãƒå‡¦ç†ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆå‹å®‰å…¨ï¼‰
export const withPooledVectors = <A, E, R>(
  count: number & Brand.Brand<'VectorCount'>,
  operation: (vectors: ReadonlyArray<Vector3>) => Effect.Effect<A, E, R>
): Effect.Effect<A, E, R | MemoryPoolService> =>
  Effect.gen(function* () {
    const pools = yield* MemoryPoolService
    const vectors = yield* Effect.all(Array.from({ length: count }, () => pools.vector3Pool.acquire()))

    try {
      const result = yield* operation(vectors)
      return result
    } finally {
      yield* Effect.all(
        vectors.map((vector) => pools.vector3Pool.release(vector)),
        { concurrency: 'unbounded' }
      )
    }
  })
```

## ğŸ’¡ Best Practices

### 1. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é§†å‹•é–‹ç™º

```typescript
// âœ… æ¨æ¸¬ã§ã¯ãªãè¨ˆæ¸¬ã«åŸºã¥ãæœ€é©åŒ–
const optimizeWithProfiling = Effect.gen(function* () {
  const profiler = yield* ProfilerService
  const session = yield* profiler.startProfiling('optimization-session')

  // ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
  const baselineResult = yield* session.measure(currentImplementation(), 'baseline-implementation')

  // æœ€é©åŒ–ç‰ˆã®ãƒ†ã‚¹ãƒˆ
  const optimizedResult = yield* session.measure(optimizedImplementation(), 'optimized-implementation')

  const report = yield* profiler.stopProfiling(session.id)

  // æ€§èƒ½æ”¹å–„ã®æ¤œè¨¼
  const improvement = ((baselineResult.duration - optimizedResult.duration) / baselineResult.duration) * 100

  // Effect-TS Matchãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹æ”¹å–„åº¦è©•ä¾¡
  yield* pipe(
    Match.value(improvement),
    Match.when(
      (value) => value < 10,
      (value) => Effect.logWarning(`Optimization showed minimal improvement: ${value.toFixed(2)}%`)
    ),
    Match.orElse((value) => Effect.logInfo(`Optimization successful: ${value.toFixed(2)}% improvement`))
  )

  return report
})
```

### 2. æ®µéšçš„æœ€é©åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

```typescript
// âœ… å°ã•ãªæ”¹å–„ã‚’ç©ã¿é‡ã­ã‚‹
const incrementalOptimization = Effect.gen(function* () {
  const optimizations = [
    { name: 'data-structure', fn: optimizeDataStructures },
    { name: 'algorithm', fn: optimizeAlgorithms },
    { name: 'memory-allocation', fn: optimizeMemoryAllocation },
    { name: 'cache-efficiency', fn: optimizeCacheEfficiency },
  ]

  let cumulativeImprovement = 0

  // Array.forEach ã«ã‚ˆã‚‹é †æ¬¡å®Ÿè¡Œï¼ˆæœ€é©åŒ–ã¯ä¾å­˜æ€§ãŒã‚ã‚‹ãŸã‚é †æ¬¡å‡¦ç†ãŒå¿…é ˆï¼‰
  yield* Effect.forEach(
    optimizations,
    (optimization) =>
      Effect.gen(function* () {
        const before = yield* measurePerformance()
        yield* optimization.fn()
        const after = yield* measurePerformance()

        const improvement = ((before.duration - after.duration) / before.duration) * 100
        cumulativeImprovement += improvement

        yield* Effect.logInfo(`${optimization.name}: ${improvement.toFixed(2)}% improvement`)
      }),
    { concurrency: 1 } // é †æ¬¡å®Ÿè¡Œã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
  )

  yield* Effect.logInfo(`Total improvement: ${cumulativeImprovement.toFixed(2)}%`)
})
```

## âš ï¸ Common Pitfalls

### 1. æ—©ã™ãã‚‹æœ€é©åŒ–

```typescript
// âŒ è¨ˆæ¸¬å‰ã®æ¨æ¸¬ã«ã‚ˆã‚‹æœ€é©åŒ–
const prematureOptimization = () => {
  // ã€Œãã£ã¨é…ã„ã¯ãšã€ã¨ã„ã†æ¨æ¸¬ã§ã‚³ãƒ¼ãƒ‰ã‚’è¤‡é›‘åŒ–
  const result = complexOptimizedFunction()
  return result
}

// âœ… è¨ˆæ¸¬ã«åŸºã¥ãå¿…è¦æœ€å°é™ã®æœ€é©åŒ–
const measuredOptimization = Effect.gen(function* () {
  const profiler = yield* ProfilerService

  // ã¾ãšç¾çŠ¶ã‚’è¨ˆæ¸¬
  const baseline = yield* profiler.measure(simpleFunction(), 'simple-version')

  // Effect-TS Matchãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹æ¡ä»¶ä»˜ãæœ€é©åŒ–
  return yield* pipe(
    Match.value(baseline.duration),
    Match.when(
      (duration) => duration > PERFORMANCE_THRESHOLD,
      () => profiler.measure(optimizedFunction(), 'optimized-version').pipe(Effect.map((result) => result.result))
    ),
    Match.orElse(() => Effect.succeed(baseline.result))
  )
})
```

### 2. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ç™ºç”Ÿ

```typescript
// âŒ ãƒªã‚½ãƒ¼ã‚¹ã®é©åˆ‡ãªè§£æ”¾ãªã—
const memoryLeakExample = Effect.gen(function* () {
  const largeArray = new Float32Array(1000000)
  const result = yield* processLargeData(largeArray)

  // largeArrayãŒå‚ç…§ã•ã‚Œç¶šã‘ã‚‹
  return { result, data: largeArray }
})

// âœ… é©åˆ‡ãªãƒªã‚½ãƒ¼ã‚¹ç®¡ç†
const properResourceManagement = Effect.gen(function* () {
  const pools = yield* MemoryPoolService
  const buffer = yield* pools.largeBufferPool.acquire()

  try {
    const result = yield* processLargeData(buffer)
    return result
  } finally {
    yield* pools.largeBufferPool.release(buffer)
  }
})
```

## ğŸ”§ Advanced Techniques

### 1. å‹•çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æ•´

```typescript
// ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ãå‹•çš„å“è³ªèª¿æ•´
const adaptivePerformanceControl = Effect.gen(function* () {
  const profiler = yield* ProfilerService
  const currentFPS = yield* profiler.getCurrentFPS()

  // Effect-TS Matchãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æ•´
  yield* pipe(
    Match.value(currentFPS),
    Match.when(
      (fps) => fps < TARGET_FPS * 0.8,
      () =>
        Effect.gen(function* () {
          // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã—ã¦ã„ã‚‹å ´åˆã¯å“è³ªã‚’ä¸‹ã’ã‚‹
          yield* Effect.logInfo('Reducing quality settings due to low FPS')
          yield* reduceRenderQuality()
          yield* decreaseParticleCount()
          yield* simplifyPhysicsCalculations()
        })
    ),
    Match.when(
      (fps) => fps > TARGET_FPS * 1.1,
      () =>
        Effect.gen(function* () {
          // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä½™è£•ãŒã‚ã‚‹å ´åˆã¯å“è³ªã‚’ä¸Šã’ã‚‹
          yield* Effect.logInfo('Increasing quality settings due to high FPS')
          yield* increaseRenderQuality()
          yield* increaseParticleCount()
          yield* enhancePhysicsCalculations()
        })
    ),
    Match.orElse(() => Effect.unit), // é©åˆ‡ãªç¯„å›²å†…ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
    Effect.flatten
  )
})
```

### 2. äºˆæ¸¬çš„æœ€é©åŒ–

```typescript
// ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãäºˆæ¸¬çš„æœ€é©åŒ–
const predictiveOptimization = Effect.gen(function* () {
  const usagePattern = yield* analyzeUsagePattern()

  if (usagePattern.indicates === 'heavy-computation-ahead') {
    // CPUãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’äº‹å‰ã«å¢—ã‚„ã™
    yield* WorkerPoolService.adjustPoolSize(usagePattern.recommendedWorkers)

    // ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚’äº‹å‰ã«æ‹¡å¼µ
    yield* MemoryPoolService.preAllocate(usagePattern.expectedMemoryUsage)
  }

  if (usagePattern.indicates === 'many-entities-spawning') {
    // ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ—ãƒ¼ãƒ«ã®æ‹¡å¼µ
    yield* expandEntityPools()

    // SoAã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®äº‹å‰ç¢ºä¿
    yield* preallocateEntityStorage(usagePattern.expectedEntityCount)
  }
})
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµ±è¨ˆã®å‹å®‰å…¨ãªå®šç¾©

```typescript
// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã®åŸºæœ¬å‹
export const FrameRateStatsSchema = Schema.Struct({
  current: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('FrameRate')),
  average: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('AverageFrameRate')),
  min: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('MinFrameRate')),
  max: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('MaxFrameRate')),
  target: Schema.Number.pipe(Schema.positive(), Schema.brand('TargetFrameRate')),
  frameDrops: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('FrameDropCount')),
}).pipe(
  Schema.filter(
    (stats) => {
      return stats.min <= stats.average && stats.average <= stats.max && stats.current >= 0
    },
    {
      message: () => 'FrameRateStats ã®çµ±è¨ˆå€¤ãŒç„¡åŠ¹ã§ã™',
    }
  ),
  Schema.identifier('FrameRateStats'),
  Schema.description('ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆçµ±è¨ˆæƒ…å ±')
)

export const MemoryStatsSchema = Schema.Struct({
  heapUsed: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('HeapUsed')),
  heapTotal: Schema.Number.pipe(Schema.positive(), Schema.brand('HeapTotal')),
  heapLimit: Schema.Number.pipe(Schema.positive(), Schema.brand('HeapLimit')),
  external: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('ExternalMemory')),
  rss: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('ResidentSetSize')),
  gcCount: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('GCCount')),
  gcTime: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('GCTime')),
}).pipe(
  Schema.filter(
    (stats) => {
      return stats.heapUsed <= stats.heapTotal && stats.heapTotal <= stats.heapLimit
    },
    {
      message: () => 'MemoryStats ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç„¡åŠ¹ã§ã™',
    }
  ),
  Schema.identifier('MemoryStats'),
  Schema.description('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡çµ±è¨ˆæƒ…å ±')
)

export const RenderingStatsSchema = Schema.Struct({
  drawCalls: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('DrawCalls')),
  triangles: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('TriangleCount')),
  vertices: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('VertexCount')),
  textureMemory: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('TextureMemory')),
  shaderPrograms: Schema.Number.pipe(Schema.int(), Schema.nonnegative(), Schema.brand('ShaderPrograms')),
  renderTime: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('RenderTime')),
}).pipe(Schema.identifier('RenderingStats'), Schema.description('ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°çµ±è¨ˆæƒ…å ±'))

export const SystemPerformanceStatsSchema = Schema.Struct({
  frameRate: FrameRateStatsSchema,
  memory: MemoryStatsSchema,
  rendering: RenderingStatsSchema,
  timestamp: Schema.Number.pipe(Schema.positive(), Schema.brand('Timestamp')),
  sessionDuration: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('SessionDuration')),
}).pipe(Schema.identifier('SystemPerformanceStats'), Schema.description('ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ'))

export type FrameRateStats = Schema.Schema.Type<typeof FrameRateStatsSchema>
export type MemoryStats = Schema.Schema.Type<typeof MemoryStatsSchema>
export type RenderingStats = Schema.Schema.Type<typeof RenderingStatsSchema>
export type SystemPerformanceStats = Schema.Schema.Type<typeof SystemPerformanceStatsSchema>

// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¾å€¤ã®å‹å®‰å…¨ãªå®šç¾©
export const PerformanceThresholdsSchema = Schema.Struct({
  criticalFPS: Schema.Number.pipe(Schema.positive(), Schema.brand('CriticalFPS')),
  warningFPS: Schema.Number.pipe(Schema.positive(), Schema.brand('WarningFPS')),
  maxMemoryUsage: Schema.Number.pipe(Schema.positive(), Schema.brand('MaxMemoryUsage')),
  maxGCTime: Schema.Number.pipe(Schema.positive(), Schema.brand('MaxGCTime')),
  maxRenderTime: Schema.Number.pipe(Schema.positive(), Schema.brand('MaxRenderTime')),
}).pipe(
  Schema.filter(
    (thresholds) => {
      return thresholds.criticalFPS < thresholds.warningFPS
    },
    {
      message: () => 'criticalFPS ã¯ warningFPS ã‚ˆã‚Šå°ã•ã„å¿…è¦ãŒã‚ã‚Šã¾ã™',
    }
  ),
  Schema.identifier('PerformanceThresholds'),
  Schema.description('ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¾å€¤è¨­å®š')
)

export type PerformanceThresholds = Schema.Schema.Type<typeof PerformanceThresholdsSchema>

// ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆã®å‹å®‰å…¨ãªå®šç¾©
export const PerformanceAlertSchema = Schema.TaggedUnion('severity', {
  critical: Schema.Struct({
    severity: Schema.Literal('critical'),
    metric: PerformanceMetricCategorySchema,
    value: Schema.Number,
    threshold: Schema.Number,
    message: Schema.String,
    timestamp: Schema.Number.pipe(Schema.brand('Timestamp')),
    actionRequired: Schema.Boolean,
  }),
  warning: Schema.Struct({
    severity: Schema.Literal('warning'),
    metric: PerformanceMetricCategorySchema,
    value: Schema.Number,
    threshold: Schema.Number,
    message: Schema.String,
    timestamp: Schema.Number.pipe(Schema.brand('Timestamp')),
    actionRequired: Schema.Boolean,
  }),
  info: Schema.Struct({
    severity: Schema.Literal('info'),
    metric: PerformanceMetricCategorySchema,
    value: Schema.Number,
    message: Schema.String,
    timestamp: Schema.Number.pipe(Schema.brand('Timestamp')),
    actionRequired: Schema.Literal(false),
  }),
}).pipe(Schema.identifier('PerformanceAlert'), Schema.description('ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆ'))

export type PerformanceAlert = Schema.Schema.Type<typeof PerformanceAlertSchema>
```

### å‹å®‰å…¨ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

```typescript
// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹
export interface PerformanceMonitorService {
  readonly startMonitoring: (config: MonitoringConfig) => Effect.Effect<void, MonitoringError>
  readonly stopMonitoring: Effect.Effect<void, never>
  readonly getCurrentStats: Effect.Effect<SystemPerformanceStats, never>
  readonly getAlertsHistory: (timeRange?: TimeRange) => Effect.Effect<ReadonlyArray<PerformanceAlert>, never>
  readonly setThresholds: (thresholds: PerformanceThresholds) => Effect.Effect<void, never>
  readonly optimizeAutomatically: (
    aggressiveness: OptimizationLevel
  ) => Effect.Effect<OptimizationResult, OptimizationError>
}

// æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«ã®å‹å®šç¾©
export const OptimizationLevelSchema = Schema.Literal('conservative', 'balanced', 'aggressive')
export type OptimizationLevel = Schema.Schema.Type<typeof OptimizationLevelSchema>

// æœ€é©åŒ–çµæœã®å‹å®šç¾©
export const OptimizationResultSchema = Schema.Struct({
  appliedOptimizations: Schema.Array(Schema.String),
  performanceImprovement: Schema.Number.pipe(
    Schema.between(-100, 1000), // -100% to 1000%
    Schema.brand('PerformanceImprovement')
  ),
  memoryReduction: Schema.Number.pipe(
    Schema.between(-100, 100), // -100% to 100%
    Schema.brand('MemoryReduction')
  ),
  executionTime: Schema.Number.pipe(Schema.nonnegative(), Schema.brand('OptimizationTime')),
  success: Schema.Boolean,
}).pipe(Schema.identifier('OptimizationResult'), Schema.description('æœ€é©åŒ–å®Ÿè¡Œçµæœ'))

export type OptimizationResult = Schema.Schema.Type<typeof OptimizationResultSchema>
```

ã“ã®ã‚¬ã‚¤ãƒ‰ã«å¾“ã†ã“ã¨ã§ã€60FPSã‚’ç¶­æŒã™ã‚‹é«˜æ€§èƒ½ãªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚²ãƒ¼ãƒ ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚ã™ã¹ã¦ã®å‹å®šç¾©ã¯Effect-TS Schemaã«ã‚ˆã£ã¦æ¤œè¨¼ã•ã‚Œã€å®Ÿè¡Œæ™‚ã®å‹å®‰å…¨æ€§ãŒä¿è¨¼ã•ã‚Œã¾ã™ã€‚
